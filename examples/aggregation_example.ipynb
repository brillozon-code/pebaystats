{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate Aggregation of Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create an array of random values and for each row of the array, we create\n",
    "a distinct ```pebaystats.dstats``` object to accumulate the descriptive statistics\n",
    "for the values in that row.\n",
    "\n",
    "Once we have the data, we can use the ```numpy``` package to generate the expected\n",
    "values for mean and variance of the data for each row.  We can also generate the\n",
    "expected mean and variance of the total data set.\n",
    "\n",
    "We then accumulate each column value for each row into its respective ```dstats``` object\n",
    "and when we have the data accumulated into these partial results, we can compare with\n",
    "the expected row values.\n",
    "\n",
    "We can then aggregate each of the row values into a final value for mean and variance\n",
    "of the entire set of data and compare to the expected value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to import the ```numpy``` package as well as the ```dstats``` class from the ```pebaystats``` package.  We import the nosetools package to allow direct comparison of expected and generated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy      as np\n",
    "import nose.tools as nt\n",
    "from pebaystats import dstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now we set the parameters, including the random seed for repeatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "### Random data size\n",
    "rows =  10\n",
    "cols = 100\n",
    "\n",
    "### Each accumulators size\n",
    "depth = 2\n",
    "width = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The test array can now be created and its shape checked.\n",
    "\n",
    "The individual row statistics and overall mean and variance can be generated as the expected\n",
    "values at this time as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data has shape: 10, 100\n"
     ]
    }
   ],
   "source": [
    "### Test data -- 10 rows of 100 columns each\n",
    "test_arr = np.random.random((rows,cols))\n",
    "\n",
    "print('Test data has shape: %d, %d' % test_arr.shape)\n",
    "\n",
    "### Expected intermediate output\n",
    "mid_mean = np.mean(test_arr,axis = 1)\n",
    "mid_var  = np.var(test_arr, axis = 1)\n",
    "\n",
    "### Expected final output\n",
    "final_mean = np.mean(test_arr)\n",
    "final_var  = np.var(test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we can create a ```dstats``` object for each row and accumulate the row data\n",
    "into its respected accumulator.  We can print the generated and expected intermediate (row)\n",
    "values to check that all is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intermediate Results\n",
      "\n",
      "Result 0 mean:    0.472794, variance:   0.0831178 (M2/N:     8.31178/100)\n",
      "Expected mean:    0.472794, variance:   0.0831178\n",
      "Result 1 mean:    0.528082, variance:   0.0765679 (M2/N:     7.65679/100)\n",
      "Expected mean:    0.528082, variance:   0.0765679\n",
      "Result 2 mean:    0.509632, variance:   0.0910113 (M2/N:     9.10113/100)\n",
      "Expected mean:    0.509632, variance:   0.0910113\n",
      "Result 3 mean:    0.472757, variance:   0.0810207 (M2/N:     8.10207/100)\n",
      "Expected mean:    0.472757, variance:   0.0810207\n",
      "Result 4 mean:    0.499723, variance:   0.0907343 (M2/N:     9.07343/100)\n",
      "Expected mean:    0.499723, variance:   0.0907343\n",
      "Result 5 mean:    0.506229, variance:   0.0906766 (M2/N:     9.06766/100)\n",
      "Expected mean:    0.506229, variance:   0.0906766\n",
      "Result 6 mean:     0.48552, variance:   0.0778794 (M2/N:     7.78794/100)\n",
      "Expected mean:     0.48552, variance:   0.0778794\n",
      "Result 7 mean:    0.468661, variance:   0.0894583 (M2/N:     8.94583/100)\n",
      "Expected mean:    0.468661, variance:   0.0894583\n",
      "Result 8 mean:    0.521702, variance:   0.0735833 (M2/N:     7.35833/100)\n",
      "Expected mean:    0.521702, variance:   0.0735833\n",
      "Result 9 mean:    0.494116, variance:   0.0864937 (M2/N:     8.64937/100)\n",
      "Expected mean:    0.494116, variance:   0.0864937\n"
     ]
    }
   ],
   "source": [
    "### Create an object for each row and accumulate the data in that row\n",
    "statsobjects = [ dstats(depth,width) for i in range(0,rows) ]\n",
    "discard = [ statsobjects[i].add(test_arr[i,j])\n",
    "            for j in range(0,cols)\n",
    "            for i in range(0,rows)]\n",
    "\n",
    "print('\\nIntermediate Results\\n')\n",
    "for i in range(0,rows):\n",
    "    values = statsobjects[i].statistics()\n",
    "    print('Result %d mean: %11g, variance: %11g (M2/N: %11g/%d)' %(i,values[0],values[1],statsobjects[i].moments[1],statsobjects[i].n))\n",
    "    print('Expected mean: %11g, variance: %11g' %(mid_mean[i],mid_var[i]))\n",
    "    nt.assert_almost_equal(values[0], mid_mean[i], places = 14)\n",
    "    nt.assert_almost_equal(values[1],  mid_var[i], places = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we can aggregate each of the intermediate row results into a final mean and\n",
    "variance value for the entire data set.  And then compare with the ```numpy```\n",
    "generated expected values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregated Results\n",
      "\n",
      "Result   mean:    0.495922, variance:   0.0844477\n",
      "Expected mean:    0.495922, variance:   0.0844477\n"
     ]
    }
   ],
   "source": [
    "### Aggregate result into the index 0 accumulator\n",
    "discard = [ statsobjects[0].aggregate(statsobjects[i]) for i in range(1,rows) ]\n",
    "\n",
    "values = statsobjects[0].statistics()\n",
    "print('\\nAggregated Results\\n')\n",
    "print('Result   mean: %11g, variance: %11g' %(values[0],values[1]))\n",
    "print('Expected mean: %11g, variance: %11g' %(final_mean,final_var))\n",
    "nt.assert_almost_equal(values[0], final_mean, places = 14)\n",
    "nt.assert_almost_equal(values[1],  final_var, places = 14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
